{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, scale, MinMaxScaler\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wgan.simulation import create_continuous_data\n",
    "from wgan.imblearn import GANbalancer\n",
    "import wgan.data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, SMOTENC\n",
    "from types import MethodType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import safe_indexing\n",
    "\n",
    "def create_samples(self, X, y):\n",
    "        # FIXME: uncomment in version 0.6\n",
    "        # self._validate_estimator()\n",
    "\n",
    "        for class_sample, n_samples in self.sampling_strategy_.items():\n",
    "            if n_samples == 0:\n",
    "                continue\n",
    "            target_class_indices = np.flatnonzero(y == class_sample)\n",
    "            X_class = safe_indexing(X, target_class_indices)\n",
    "\n",
    "            self.nn_k_.fit(X_class)\n",
    "            nns = self.nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]\n",
    "            X_new, y_new = self._make_samples(X_class, y.dtype, class_sample,\n",
    "                                              X_class, nns, n_samples, 1.0)\n",
    "\n",
    "        return X_new, y_new\n",
    "\n",
    "\n",
    "SMOTE._sample_only = create_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifical Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 5000\n",
    "N_VAR = 6\n",
    "data = {\n",
    "    \"Independent\" : create_continuous_data(n_samples=N_SAMPLES, n_var=N_VAR, n_dependent=0, pos_ratio=0),\n",
    "    \"Dependent\" : create_continuous_data(n_samples=N_SAMPLES, n_var=N_VAR, n_dependent=5, pos_ratio=0),\n",
    "    \"Mixed\" : create_continuous_data(n_samples=N_SAMPLES, n_var=N_VAR, n_dependent=N_VAR//2, pos_ratio=0)\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_balancer = GANbalancer(idx_cont=range(N_VAR), categorical=None, auxiliary=False,\n",
    "                           gan_architecture = \"fisher\",\n",
    "                           generator_input=N_VAR*1, generator_layers=None, \n",
    "                           critic_layers=[N_VAR, N_VAR], critic_iterations=5,\n",
    "                           learning_rate = [1e-4, 1e-4],\n",
    "                           batch_size = 128, n_iter=20000, \n",
    "                           sampling_strategy = {0:N_SAMPLES, 1:0}, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy = {0:N_SAMPLES, 1:0})\n",
    "smote._validate_estimator()\n",
    "smote.sampling_strategy_ = {0:N_SAMPLES, 1:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_first_moments(X):\n",
    "    return np.vstack([x.mean(axis=0) for x in X])\n",
    "\n",
    "def check_second_moments(X):\n",
    "    return [np.cov(x, rowvar=False).round(2) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Normal RVs - First and Second Moment Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 992/20000 [00:16<05:13, 60.63it/s]"
     ]
    }
   ],
   "source": [
    "gan_balancer._fit(data[\"Independent\"][0], y=np.zeros(shape=N_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'G': [tensor(-1.1528), tensor(-1.3391)],\n",
       " 'D': [tensor(-0.4317),\n",
       "  tensor(-0.4829),\n",
       "  tensor(-0.4407),\n",
       "  tensor(-0.6962),\n",
       "  tensor(-0.5976),\n",
       "  tensor(-0.5826),\n",
       "  tensor(-0.6053),\n",
       "  tensor(-0.5494),\n",
       "  tensor(-0.3381),\n",
       "  tensor(-0.5043),\n",
       "  tensor(-0.4622),\n",
       "  tensor(-0.6393),\n",
       "  tensor(-0.5324),\n",
       "  tensor(-0.7401),\n",
       "  tensor(-0.5125),\n",
       "  tensor(-0.6360),\n",
       "  tensor(-0.5325),\n",
       "  tensor(-0.6186),\n",
       "  tensor(-0.5991),\n",
       "  tensor(-0.7069),\n",
       "  tensor(-0.6421),\n",
       "  tensor(-0.3994),\n",
       "  tensor(-0.6229),\n",
       "  tensor(-0.5511),\n",
       "  tensor(-0.3153),\n",
       "  tensor(-0.3852),\n",
       "  tensor(-0.4174),\n",
       "  tensor(-0.4324),\n",
       "  tensor(-0.6394),\n",
       "  tensor(-0.5331)],\n",
       " 'GP': [tensor(4.8033),\n",
       "  tensor(4.1388),\n",
       "  tensor(4.1832),\n",
       "  tensor(4.1107),\n",
       "  tensor(3.6244),\n",
       "  tensor(4.1233),\n",
       "  tensor(3.7706),\n",
       "  tensor(3.5861),\n",
       "  tensor(4.3956),\n",
       "  tensor(4.7931),\n",
       "  tensor(3.8608),\n",
       "  tensor(3.9352),\n",
       "  tensor(4.1312),\n",
       "  tensor(4.0797),\n",
       "  tensor(5.0485),\n",
       "  tensor(5.1218),\n",
       "  tensor(4.1905),\n",
       "  tensor(4.0120),\n",
       "  tensor(4.1162),\n",
       "  tensor(4.5808),\n",
       "  tensor(3.8066),\n",
       "  tensor(4.6848),\n",
       "  tensor(4.2612),\n",
       "  tensor(3.8395),\n",
       "  tensor(4.7316),\n",
       "  tensor(1.1375),\n",
       "  tensor(1.1577),\n",
       "  tensor(1.4029),\n",
       "  tensor(1.6720),\n",
       "  tensor(1.3249)],\n",
       " 'distance': [tensor(0.4317),\n",
       "  tensor(0.4829),\n",
       "  tensor(0.4407),\n",
       "  tensor(0.6962),\n",
       "  tensor(0.5976),\n",
       "  tensor(0.5826),\n",
       "  tensor(0.6053),\n",
       "  tensor(0.5494),\n",
       "  tensor(0.3381),\n",
       "  tensor(0.5043),\n",
       "  tensor(0.4622),\n",
       "  tensor(0.6393),\n",
       "  tensor(0.5324),\n",
       "  tensor(0.7401),\n",
       "  tensor(0.5125),\n",
       "  tensor(0.6360),\n",
       "  tensor(0.5325),\n",
       "  tensor(0.6186),\n",
       "  tensor(0.5991),\n",
       "  tensor(0.7069),\n",
       "  tensor(0.6421),\n",
       "  tensor(0.3994),\n",
       "  tensor(0.6229),\n",
       "  tensor(0.5511),\n",
       "  tensor(0.3153),\n",
       "  tensor(0.3852),\n",
       "  tensor(0.4174),\n",
       "  tensor(0.4324),\n",
       "  tensor(0.6394),\n",
       "  tensor(0.5331)],\n",
       " 'gradient_norm': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_balancer.trainer.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8146e653fc6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_balancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1803\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1889\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \"\"\"\n\u001b[0;32m-> 1913\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \"\"\"\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/deeplearning/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gan_balancer.trainer.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [00:01, 65.96it/s]                        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GANbalancer(auxiliary=False, batch_size=128, categorical=None,\n",
       "      critic_iterations=5, critic_layers=[6, 6],\n",
       "      gan_architecture='vanilla', generator_input=6, generator_layers=None,\n",
       "      idx_cont=range(0, 6), learning_rate=[0.0001, 0.0001], n_iter=10000,\n",
       "      random_state=None, sampling_strategy={0: 5000, 1: 0}, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_balancer._update(data[\"Independent\"][0], y=np.zeros(shape=N_SAMPLES), n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24558693,  0.94326149,  0.14457229,  1.02345628, -0.01053431,\n",
       "         0.32309668],\n",
       "       [ 0.45241073,  0.44158989,  0.99552757,  1.2545588 ,  0.29310697,\n",
       "         0.74577874],\n",
       "       [ 0.24408541,  0.95446533,  0.13857254,  1.02729823, -0.00205774,\n",
       "         0.32454183]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_first_moments([data[\"Independent\"][0], \n",
    "                     gan_balancer.generator.sample_data(N_SAMPLES),\n",
    "                     smote._sample(data[\"Independent\"][0], y=np.zeros(shape=N_SAMPLES))[0]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3122, -0.0970, -0.2457,  0.7639,  0.0792, -0.7601],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gan_balancer.generator.parameters())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.98,  0.01, -0.03, -0.02,  0.02,  0.  ],\n",
       "        [ 0.01,  1.  , -0.01,  0.  ,  0.  ,  0.  ],\n",
       "        [-0.03, -0.01,  1.03,  0.  , -0.04,  0.  ],\n",
       "        [-0.02,  0.  ,  0.  ,  1.05, -0.  , -0.02],\n",
       "        [ 0.02,  0.  , -0.04, -0.  ,  1.  ,  0.01],\n",
       "        [ 0.  ,  0.  ,  0.  , -0.02,  0.01,  1.03]]),\n",
       " array([[ 0.08, -0.  ,  0.01, -0.01, -0.  , -0.01],\n",
       "        [-0.  ,  0.07,  0.  , -0.01,  0.01, -0.  ],\n",
       "        [ 0.01,  0.  ,  0.08,  0.  , -0.01, -0.01],\n",
       "        [-0.01, -0.01,  0.  ,  0.07, -0.  , -0.  ],\n",
       "        [-0.  ,  0.01, -0.01, -0.  ,  0.07, -0.01],\n",
       "        [-0.01, -0.  , -0.01, -0.  , -0.01,  0.07]]),\n",
       " array([[ 0.93,  0.01, -0.03, -0.02,  0.03, -0.01],\n",
       "        [ 0.01,  0.94, -0.01,  0.01,  0.02,  0.  ],\n",
       "        [-0.03, -0.01,  0.98,  0.01, -0.05,  0.02],\n",
       "        [-0.02,  0.01,  0.01,  1.  , -0.  , -0.01],\n",
       "        [ 0.03,  0.02, -0.05, -0.  ,  0.93, -0.  ],\n",
       "        [-0.01,  0.  ,  0.02, -0.01, -0.  ,  0.98]])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_second_moments([data[\"Independent\"][0], \n",
    "                     gan_balancer.generator.sample_data(N_SAMPLES),\n",
    "                     smote._sample(data[\"Independent\"][0], y=np.zeros(shape=N_SAMPLES))[0]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(gan_balancer.generator.parameters())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Normal RVs - Covariance Approximation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = \"Dependent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:45<00:00, 61.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GANbalancer(auxiliary=False, batch_size=128, categorical=None,\n",
       "      critic_iterations=5, critic_layers=[6, 6],\n",
       "      gan_architecture='vanilla', generator_input=6, generator_layers=None,\n",
       "      idx_cont=range(0, 6), learning_rate=[0.0001, 0.0001], n_iter=10000,\n",
       "      random_state=None, sampling_strategy={0: 5000, 1: 0}, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_balancer._fit(data[data_idx][0], y=np.zeros(shape=N_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12093273, -1.30830406,  0.03254741, -0.99050832,  0.37988856,\n",
       "         0.15066954],\n",
       "       [-0.46871793, -0.10228445,  0.20485757, -0.61921126,  0.31055045,\n",
       "         0.92625159],\n",
       "       [-0.1162044 , -1.30777855,  0.02847206, -0.98962923,  0.38538739,\n",
       "         0.15110139]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_first_moments([data[data_idx][0], \n",
    "                     gan_balancer.generator.sample_data(N_SAMPLES),\n",
    "                     smote._sample(data[data_idx][0], y=np.zeros(shape=N_SAMPLES))[0]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance matrix extimate is very close to true covariance matrix, e.g. \n",
    "TRUE  ([[ 0.21, -0.11, -0.11, -0.14,  0.1 ],\n",
    "        [-0.11,  0.32,  0.08,  0.07, -0.23],\n",
    "        [-0.11,  0.08,  0.13,  0.11, -0.08],\n",
    "        [-0.14,  0.07,  0.11,  0.21, -0.07],\n",
    "        [ 0.1 , -0.23, -0.08, -0.07,  0.24]]),\n",
    "        \n",
    " GAN  ([[ 0.21, -0.09, -0.12, -0.17,  0.11],\n",
    "        [-0.09,  0.23,  0.07,  0.07, -0.14],\n",
    "        [-0.12,  0.07,  0.13,  0.13, -0.06],\n",
    "        [-0.17,  0.07,  0.13,  0.21, -0.06],\n",
    "        [ 0.11, -0.14, -0.06, -0.06,  0.2 ]]),\n",
    "        \n",
    "SMOTE ([[ 0.21, -0.11, -0.11, -0.14,  0.1 ],\n",
    "        [-0.11,  0.32,  0.08,  0.07, -0.23],\n",
    "        [-0.11,  0.08,  0.13,  0.11, -0.08],\n",
    "        [-0.14,  0.07,  0.11,  0.21, -0.07],\n",
    "        [ 0.1 , -0.23, -0.08, -0.07,  0.23]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.02, -0.  , -0.01,  0.  ,  0.01,  0.  ],\n",
       "        [-0.  ,  0.13, -0.02,  0.04, -0.05, -0.  ],\n",
       "        [-0.01, -0.02,  0.16, -0.02, -0.03, -0.03],\n",
       "        [ 0.  ,  0.04, -0.02,  0.12, -0.01,  0.02],\n",
       "        [ 0.01, -0.05, -0.03, -0.01,  0.15,  0.04],\n",
       "        [ 0.  , -0.  , -0.03,  0.02,  0.04,  0.08]]),\n",
       " array([[ 0.08, -0.02, -0.  ,  0.01,  0.02, -0.  ],\n",
       "        [-0.02,  0.26, -0.  ,  0.13, -0.04,  0.13],\n",
       "        [-0.  , -0.  ,  0.02,  0.  , -0.01, -0.01],\n",
       "        [ 0.01,  0.13,  0.  ,  0.08, -0.03,  0.05],\n",
       "        [ 0.02, -0.04, -0.01, -0.03,  0.02, -0.01],\n",
       "        [-0.  ,  0.13, -0.01,  0.05, -0.01,  0.09]]),\n",
       " array([[ 1.02, -0.  , -0.  ,  0.  ,  0.01,  0.  ],\n",
       "        [-0.  ,  0.13, -0.02,  0.04, -0.05, -0.  ],\n",
       "        [-0.  , -0.02,  0.15, -0.02, -0.03, -0.03],\n",
       "        [ 0.  ,  0.04, -0.02,  0.11, -0.01,  0.02],\n",
       "        [ 0.01, -0.05, -0.03, -0.01,  0.14,  0.04],\n",
       "        [ 0.  , -0.  , -0.03,  0.02,  0.04,  0.07]])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_second_moments([data[data_idx][0], \n",
    "                     gan_balancer.generator.sample_data(N_SAMPLES),\n",
    "                     smote._sample(data[data_idx][0], y=np.zeros(shape=N_SAMPLES))[0]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critic data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the critic to select samples that are more realistic from a larger set of generated observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gan_balancer.generator(gan_balancer.generator.sample_latent(N_SAMPLES*20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_critic = np.argsort(\n",
    "    gan_balancer.critic(sample).detach().numpy().flatten()\n",
    "                         )\n",
    "idx_lowest = idx_critic[:N_SAMPLES].copy()\n",
    "idx_highest = idx_critic[-N_SAMPLES:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critic output is in the range $[-\\inf;0]$ where higher is less difference to the real distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_np = sample.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lowest = sample_np[idx_lowest,:].copy()\n",
    "sample_random = sample_np[np.random.choice(range(0,N_SAMPLES), size=N_SAMPLES),:].copy()\n",
    "sample_highest = sample_np[idx_highest,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_first_moments([data[\"Independent\"][0], \n",
    "                     sample_highest,\n",
    "                     sample_np,\n",
    "                     sample_lowest\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_second_moments([data[\"Independent\"][0], \n",
    "                     sample_highest,\n",
    "                     sample_np,\n",
    "                     sample_lowest\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = [(x,y) for x in range(no_vars) for y in range(no_vars) if y>x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=no_vars, ncols=no_vars, sharex=True, sharey=True, squeeze=True,figsize=(10,10))\n",
    "for y in axes:\n",
    "    for x in y:\n",
    "        x.set_xticklabels([])\n",
    "        x.set_yticklabels([])\n",
    "\n",
    "for i,j in combinations:\n",
    "    sns.kdeplot(X_majority[:,i], X_majority[:,j], alpha=0.5, cmap=\"Blues\", ax=axes[(j,i)])\n",
    "    sns.kdeplot(X_minority[:,i], X_minority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(j,i)])\n",
    "fig.savefig(f'../img/cont_sample_tr_iter_{trainer.G.training_iterations}.png',format='png', dpi=100)\n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 90\n",
    "\n",
    "for _ in range(30):\n",
    "    trainer.train(data_loader, epochs)\n",
    "    \n",
    "    \n",
    "    if modus == 'full':\n",
    "        fake_minority = generator(*generator.sample_latent(num_samples= 1000, class_index=1)).data.numpy()\n",
    "        fake_majority = generator(*generator.sample_latent(num_samples= 1000, class_index=0)).data.numpy()\n",
    "    elif modus == 'minority':\n",
    "        fake_minority = generator(generator.sample_latent(num_samples= 1000)).data.numpy()\n",
    "        \n",
    "    fig, axes = plt.subplots(nrows=no_vars, ncols=no_vars, sharex=True, squeeze=True,figsize=(10,10))\n",
    "    for y in axes:\n",
    "        for x in y:\n",
    "            x.set_xticklabels([])\n",
    "            x.set_yticklabels([])\n",
    "    \n",
    "    for i in range(no_vars):\n",
    "        sns.kdeplot(X_minority[:,i], alpha=0.5, shade=True, color=\"blue\", ax=axes[(i,i)])\n",
    "        sns.kdeplot(fake_minority[:,i], alpha=0.5, shade=True, color=\"green\", ax=axes[(i,i)])\n",
    "    \n",
    "    for i,j in combinations:\n",
    "        axes[(i,j)].set_ylim(0,1)\n",
    "        # majority (upper right)\n",
    "        if modus == 'full':\n",
    "            sns.kdeplot(X_majority[0:1000,i], X_majority[0:1000,j], alpha=0.5, cmap=\"Blues\", ax=axes[(i,j)])\n",
    "            sns.kdeplot(fake_majority[:,i], fake_majority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(i,j)], )\n",
    "        \n",
    "        # minority (lower left)\n",
    "        sns.kdeplot(X_minority[:,i], X_minority[:,j], alpha=0.5, cmap=\"Blues\", ax=axes[(j,i)])\n",
    "        sns.kdeplot(fake_minority[:,i], fake_minority[:,j], alpha=0.5, cmap=\"Greens\", ax=axes[(j,i)])\n",
    "        \n",
    "    fig.savefig(f'../img/cont_sample_tr_iter_{trainer.G.training_iterations}.png',format='png', dpi=200)\n",
    "        #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = f\"multinormal_n{N//1000}_k{no_vars}_{modus}\"\n",
    "torch.save(generator.state_dict(), f\"../models/wgan_generator_{desc}_{generator.training_iterations}\")\n",
    "torch.save(discriminator.state_dict(), f\"../models/wgan_discriminator_{desc}_{generator.training_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"multinormal_n10_k4_c2_6999\"\n",
    "generator.load_state_dict(torch.load(f\"../models/wgan_generator_{file_name}\"))\n",
    "discriminator.load_state_dict(torch.load(f\"../models/wgan_discriminator_{file_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_minority = generator(*generator.sample_latent(num_samples= minority_samples, class_index=1)).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_minority, axis=0))\n",
    "print(np.mean(fake_minority, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.quantile(X_minority, q=np.arange(0,1,0.1), axis=0))\n",
    "print(np.quantile(fake_minority, q=np.arange(0,1,0.1), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.cov(X_minority, rowvar=False) - np.cov(fake_minority,rowvar=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = X_minority.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = generator(*generator.sample_latent(num_samples= sample_size, class_index=1)).data.numpy()\n",
    "#fake = generator(generator.sample_latent(num_samples= sample_size)).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fakereal = np.vstack([X_minority, \n",
    "                        fake])\n",
    "y_fakereal = np.concatenate([np.zeros(X_minority.shape[0]), \n",
    "                        np.ones(fake.shape[0])]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, min_samples_leaf=20, n_jobs=10)\n",
    "model_fakereal = clf.fit(X_fakereal, y_fakereal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fakereal = model_fakereal.predict_proba(X_fakereal)[:,1]\n",
    "roc_auc_score(y_fakereal, pred_fakereal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive performance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = np.argmax(y_train, axis=1)\n",
    "y_test_bin = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_auc(model_library, X, y_true):\n",
    "    auc = {}\n",
    "    for model in model_library.keys():\n",
    "        pred = model_library[model].predict_proba(X_test)[:,1]\n",
    "        auc[model] = roc_auc_score(y_true, pred)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_samples = X_minority.shape[0]\n",
    "majority_samples = X_majority.shape[0]\n",
    "\n",
    "fake_minority = generator(*generator.sample_latent(num_samples= minority_samples, class_index=1)).data.numpy()\n",
    "fake_majority = generator(*generator.sample_latent(num_samples= majority_samples, class_index=0)).data.numpy()\n",
    "\n",
    "X_synthetic = np.vstack([fake_majority, \n",
    "                         fake_minority])\n",
    "y_synthetic = np.concatenate([np.zeros(majority_samples), \n",
    "                              np.ones(minority_samples)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_org = DecisionTreeClassifier(max_depth=10) #LogisticRegression(solver='saga') \n",
    "clf_fake = DecisionTreeClassifier(max_depth=10) #LogisticRegression(solver='saga')\n",
    "\n",
    "predictive = {}\n",
    "predictive[\"real\"] = clf_org.fit(X=X_train, y=y_train_bin)\n",
    "predictive[\"synthetic\"] = clf_fake.fit(X=X_synthetic, y=y_synthetic)\n",
    "\n",
    "test_auc(predictive, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\"original\":[],\"GANbalanced\":[]}\n",
    "for i in range(200):\n",
    "    sample_size = X_minority.shape[0]*4\n",
    "    X_fake = generator(*generator.sample_latent(num_samples= sample_size, class_index=1)).data.numpy()\n",
    "    #X_fake = generator(generator.sample_latent(num_samples= sample_size, class_index=None)).data.numpy()\n",
    "    y_fake = np.ones(shape=[sample_size])\n",
    "\n",
    "    X_up = np.vstack([X_train,X_fake])\n",
    "    y_up = np.hstack([y_train_bin,y_fake])\n",
    "\n",
    "    clf_org = DecisionTreeClassifier(max_depth=5)\n",
    "    clf_fake = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "    upsampling = {}\n",
    "    upsampling[\"original\"] =  clf_org.fit(X=X_train, y=y_train_bin)\n",
    "    upsampling[\"GANbalanced\"] = clf_fake.fit(X=X_up, y=y_up)\n",
    "    \n",
    "    performance_temp = test_auc(upsampling, X_test, y_test_bin)\n",
    "    for model in performance_temp:\n",
    "        performance[model].append(performance_temp[model])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(performance).mean())\n",
    "print(pd.DataFrame(performance).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_function(X, y, clf, ax):\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.8, c=y, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "plot_decision_function(X_train, y_train, upsampling[\"original\"], ax1)\n",
    "plot_decision_function(X_up, y_up, upsampling[\"GANbalanced\"], ax2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
